# (c) 2016 DataNexus Inc.  All Rights Reserved
---
# First, build our telegraf and kafka host groups
- name: Create telegraf and kafka host groups
  hosts: "{{host_inventory}}"
  gather_facts: no
  tasks:
    - include_role:
        name: build-app-host-groups
      vars:
        host_group_list:
          - name: telegraf
          - name: kafka
      when: cloud == 'aws' or cloud == 'osp'
    - include_role:
        name: build-app-host-groups
      vars:
        host_group_list:
          - { name: telegraf, node_list: "{{host_inventory}}" }
          - { name: kafka, inventory: "{{kafka_inventory | default({})}}", node_list: "{{kafka_nodes | default([])}}" }
      when: cloud == 'vagrant'

# Collect the 'hostvars' facts from the kafka host group
- name: Gather facts from kafka host group
  hosts: kafka
  tasks: []

# Then, deploy our Telegraf agents to the nodes in the `host_inventory` that was passed in
- name: Install/configure telegraf agents
  hosts: telegraf
  gather_facts: no
  vars_files:
    - vars/telegraf.yml
  vars:
    - combined_package_list: "{{ (default_packages|default([])) | union(telegraf_package_list|default([])) | union((install_packages_by_tag|default({})).telegraf|default([])) }}"
  # First, restart the network (unless the skip_network_restart was set)
  # and gather some facts about our Telegraf node(s)
  pre_tasks:
    - name: Ensure the network interfaces are up on our Telegraf node(s)
      service:
        name: network
        state: restarted
      become: true
      when: not (skip_network_restart is defined or skip_network_restart)
    - name: Gather facts from the Telegraf node(s)
      setup:
    # in these two steps, we obtain the interface names for our data_iface
    # and api_iface (provided an interface description was provided for each)
    - include_role:
        name: get-iface-names
      vars:
        iface_descriptions: "{{iface_description_array}}"
      when: not (iface_description_array is undefined or iface_description_array == [])
    # and now that we know we have our data_iface identified, we can construct
    # the list of zk_nodes (the data_iface IP addresses of our kafka_nodes)
    - set_fact:
        kfka_nodes: "{{(kafka_nodes | default([])) | map('extract', hostvars, [('ansible_' + data_iface), 'ipv4', 'address']) | list}}"
    # if we're provisioning a RHEL machine, then we need to ensure that
    # it's subscribed before we can install anything (if it hasn't been
    # registered already, of course, if that's the case then we can skip
    # this step)
    - block:
      - redhat_subscription:
          state: present
          username: "{{rhel_username}}"
          password: "{{rhel_password}}"
          consumer_id: "{{rhel_consumer_id}}"
        become: true
        when: rhel_username is defined and rhel_password is defined and rhel_consumer_id is defined
      when: ansible_distribution == 'RedHat'
  # Now that we have all of the facts we need, run the roles that are used to
  # deploy and configure Telegraf
  roles:
    - role: get-iface-addr
      iface_name: "{{data_iface}}"
      as_fact: "data_addr"
    - role: setup-web-proxy
    - role: add-local-repository
      yum_repository: "{{yum_repo_url}}"
      when: yum_repo_url is defined and ansible_distribution != 'RedHat'
    - role: install-packages
      package_list: "{{combined_package_list}}"
    - role: add-package-repo
      package_name: influxdb
      repo_name: "InfluxDB Repository"
      repo_url: "https://repos.influxdata.com/rhel/$releasever/$basearch/stable"
      repo_key_url: "https://repos.influxdata.com/influxdb.key"
    - dn-telegraf
